{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "624d8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from nanopq import PQ\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fa4c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define text passages\n",
    "passages = {\n",
    "    \"doc1\": \"Artificial intelligence is transforming industries.\",\n",
    "    \"doc2\": \"Machine learning helps computers learn from data.\",\n",
    "    \"doc3\": \"Quantum computing is a new paradigm.\",\n",
    "    \"doc4\": \"The future of AI includes ethical challenges.\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d2d6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load GTR-T5-Base sentence encoder\n",
    "model = SentenceTransformer(\"sentence-transformers/gtr-t5-base\")\n",
    "docids = list(passages.keys())\n",
    "texts = list(passages.values())\n",
    "embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe959aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 768),\n",
       " dtype('float32'),\n",
       " array([[ 0.00273099, -0.0302944 ,  0.05884   , ...,  0.03470925,\n",
       "         -0.01520736,  0.03500362],\n",
       "        [-0.02251787, -0.05412124,  0.05713512, ...,  0.00543885,\n",
       "          0.00965429, -0.01286693],\n",
       "        [ 0.01178704, -0.01564313,  0.01263544, ..., -0.0136919 ,\n",
       "         -0.00466294,  0.01595624],\n",
       "        [ 0.01346409, -0.00766769,  0.01716973, ..., -0.00420209,\n",
       "         -0.02281265,  0.05193746]], dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, embeddings.dtype, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31c665a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 6, Ks: 2, metric : <class 'numpy.uint8'>, code_dtype: l2\n",
      "iter: 20, seed: 123\n",
      "Training the subspace: 0 / 6\n",
      "Training the subspace: 1 / 6\n",
      "Training the subspace: 2 / 6\n",
      "Training the subspace: 3 / 6\n",
      "Training the subspace: 4 / 6\n",
      "Training the subspace: 5 / 6\n",
      "Encoding the subspace: 0 / 6\n",
      "Encoding the subspace: 1 / 6\n",
      "Encoding the subspace: 2 / 6\n",
      "Encoding the subspace: 3 / 6\n",
      "Encoding the subspace: 4 / 6\n",
      "Encoding the subspace: 5 / 6\n"
     ]
    }
   ],
   "source": [
    "# 3. Setup Product Quantization\n",
    "# Ensure the number of training vectors is sufficient for Ks\n",
    "pq = PQ(M=6, Ks=2)  # 6 subspaces of 128-dim vectors = 768 total dim\n",
    "pq.fit(embeddings)\n",
    "\n",
    "# 4. Encode with PQ\n",
    "codes = pq.encode(embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5610dddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 6),\n",
       " dtype('uint8'),\n",
       " array([[1, 1, 0, 1, 1, 1],\n",
       "        [1, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 1],\n",
       "        [0, 1, 1, 0, 1, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes.shape, codes.dtype, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c66a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized PQ DocIDs:\n",
      "doc1\t32129,32385,32640,32897,33153,33409\n",
      "doc2\t32129,32384,32640,32897,33152,33409\n",
      "doc3\t32128,32384,32640,32897,33152,33409\n",
      "doc4\t32128,32385,32641,32896,33153,33408\n"
     ]
    }
   ],
   "source": [
    "# 5. Simulate T5 vocab offset\n",
    "mock_vocab_size = 32128\n",
    "\n",
    "# 6. Print encoded docids\n",
    "print(\"Quantized PQ DocIDs:\")\n",
    "encoded_ids = []\n",
    "for idx, code in enumerate(codes):\n",
    "    new_doc_code = [int(x) + i * 256 for i, x in enumerate(code)]\n",
    "    encoded = ','.join(str(x + mock_vocab_size) for x in new_doc_code)\n",
    "    encoded_ids.append(encoded)\n",
    "    print(f\"{docids[idx]}\\t{encoded}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8797ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Decode the encoded IDs back to quantized codes\n",
    "decoded_codes = []\n",
    "for encoded in encoded_ids:\n",
    "    new_doc_code = [int(x) - mock_vocab_size for x in encoded.split(',')]\n",
    "    quantized_code = [new_doc_code[i] % pq.Ks for i in range(pq.M)]  # Ensure values are within [0, Ks-1]\n",
    "    decoded_codes.append(quantized_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc446e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy array with the correct shape and dtype\n",
    "decoded_codes = np.array(decoded_codes, dtype=np.uint8)\n",
    "\n",
    "# Verify the shape and dtype of decoded_codes\n",
    "assert decoded_codes.shape[1] == pq.M, f\"Expected {pq.M} subspaces, got {decoded_codes.shape[1]}\"\n",
    "assert decoded_codes.dtype == pq.code_dtype, f\"Expected dtype {pq.code_dtype}, got {decoded_codes.dtype}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3673411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Reconstruct embeddings using PQ\n",
    "reconstructed_embeddings = pq.decode(decoded_codes)\n",
    "\n",
    "# 9. Normalize embeddings for cosine similarity\n",
    "embeddings = normalize(embeddings, axis=1)\n",
    "reconstructed_embeddings = normalize(reconstructed_embeddings, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ca4e434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 768),\n",
       " dtype('float32'),\n",
       " array([[-0.01120163, -0.04778889,  0.06565516, ...,  0.00998482,\n",
       "         -0.00385562,  0.01437663],\n",
       "        [-0.01128512, -0.04814507,  0.0661445 , ...,  0.01005924,\n",
       "         -0.00388436,  0.01448378],\n",
       "        [ 0.0145317 , -0.01341508,  0.0171525 , ...,  0.01015014,\n",
       "         -0.00391946,  0.01461466],\n",
       "        [ 0.01323483, -0.01221786,  0.01562174, ..., -0.00440487,\n",
       "         -0.02391352,  0.0544438 ]], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_embeddings.shape, reconstructed_embeddings.dtype, reconstructed_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e33c73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 10. Compute cosine similarity\n",
    "similarities = cosine_similarity(reconstructed_embeddings, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db2db764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoded IDs and their closest texts:\n",
      "Decoded text for doc 1: Artificial intelligence is transforming industries.\n",
      "Similarity scores for doc 1:\n",
      "  Text 1: Artificial intelligence is transforming industries. (Similarity: 0.8896)\n",
      "  Text 2: Machine learning helps computers learn from data. (Similarity: 0.7894)\n",
      "  Text 3: Quantum computing is a new paradigm. (Similarity: 0.7352)\n",
      "  Text 4: The future of AI includes ethical challenges. (Similarity: 0.7704)\n",
      "Decoded text for doc 2: Machine learning helps computers learn from data.\n",
      "Similarity scores for doc 2:\n",
      "  Text 1: Artificial intelligence is transforming industries. (Similarity: 0.8200)\n",
      "  Text 2: Machine learning helps computers learn from data. (Similarity: 0.8717)\n",
      "  Text 3: Quantum computing is a new paradigm. (Similarity: 0.8220)\n",
      "  Text 4: The future of AI includes ethical challenges. (Similarity: 0.6684)\n",
      "Decoded text for doc 3: Quantum computing is a new paradigm.\n",
      "Similarity scores for doc 3:\n",
      "  Text 1: Artificial intelligence is transforming industries. (Similarity: 0.7815)\n",
      "  Text 2: Machine learning helps computers learn from data. (Similarity: 0.8292)\n",
      "  Text 3: Quantum computing is a new paradigm. (Similarity: 0.8677)\n",
      "  Text 4: The future of AI includes ethical challenges. (Similarity: 0.7009)\n",
      "Decoded text for doc 4: The future of AI includes ethical challenges.\n",
      "Similarity scores for doc 4:\n",
      "  Text 1: Artificial intelligence is transforming industries. (Similarity: 0.7385)\n",
      "  Text 2: Machine learning helps computers learn from data. (Similarity: 0.5953)\n",
      "  Text 3: Quantum computing is a new paradigm. (Similarity: 0.6516)\n",
      "  Text 4: The future of AI includes ethical challenges. (Similarity: 0.9537)\n"
     ]
    }
   ],
   "source": [
    "# 11. Print all decoded IDs and their closest texts\n",
    "print(\"\\nDecoded IDs and their closest texts:\")\n",
    "for i, sim in enumerate(similarities):\n",
    "    closest_idx = np.argmax(sim)  # Index of the most similar embedding\n",
    "    print(f\"Decoded text for doc {i + 1}: {texts[closest_idx]}\")\n",
    "    print(f\"Similarity scores for doc {i + 1}:\")\n",
    "    for j, score in enumerate(sim):\n",
    "        print(f\"  Text {j + 1}: {texts[j]} (Similarity: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d12645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddro_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
